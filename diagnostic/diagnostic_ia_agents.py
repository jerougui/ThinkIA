import sys
import os

# üìÅ Acc√®s aux modules du projet
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from tools.sablier import Sablier
from tools.ollama_manager import launch_model_if_needed
from config.config import PROVIDER
from tools.llm_provider import chat

MAX_QUESTIONS = 5

def collect_static_patient_info():
    print("ü©∫ Veuillez r√©pondre aux questions suivantes :\n")
    nom = input("Nom du patient : ").strip()
    age = input("√Çge du patient : ").strip()
    sexe = input("Sexe (H/F) : ").strip()
    poids = input("Poids (kg) : ").strip()
    taille = input("Taille (cm) : ").strip()
    return f"nomm√©(e) {nom}, √¢g√©(e) de {age} ans, de sexe {sexe}, pesant {poids} kg pour {taille} cm."

def generate_context_and_questions(topic, profil_patient):
    conversation = [{
        "role": "system",
        "content": (
            f"Tu es un m√©decin g√©n√©raliste empathique et exp√©riment√©. "
            f"Tu interroges un patient {profil_patient} sur le sujet '{topic}' pour √©tablir un diagnostic. "
            f"√Ä chaque question, tu t'appuies sur les r√©ponses pr√©c√©dentes pour affiner la suivante sans jamais te r√©p√©ter."
        )
    }]

    resultats = []
    for i in range(MAX_QUESTIONS):
        if i == 0:
            prompt_utilisateur = (
                f"Commence par poser une premi√®re question pertinente et claire sur '{topic}'. "
                "Ne pose qu‚Äôune seule question √† la fois."
            )
        else:
            historique = "\n".join(
                [f"{j+1}. Q: {r['question']}\n   R: {r['reponse']}" for j, r in enumerate(resultats)]
            )
            prompt_utilisateur = (
                f"Voici l‚Äôhistorique des √©changes avec le patient :\n{historique}\n\n"
                f"Pose maintenant une nouvelle question utile sur '{topic}', en √©vitant les doublons, "
                f"et en tenant compte des r√©ponses pr√©c√©dentes. Ne propose qu‚Äôune seule question."
            )

        conversation.append({"role": "user", "content": prompt_utilisateur})
        sablier = Sablier(message=f"ü§ñ R√©flexion sur la question {i+1}/{MAX_QUESTIONS}...")
        sablier.start()
        response = chat(messages=conversation)  # ‚úÖ mod√®le choisi automatiquement
        sablier.stop()

        question = response["message"]["content"]
        print(f"\nüß† Question {i+1} : {question}")
        reponse_patient = input("‚úèÔ∏è Votre r√©ponse : ").strip()

        resultats.append({
            "question": question,
            "reponse": reponse_patient
        })

        conversation.append({"role": "assistant", "content": question})
        conversation.append({"role": "user", "content": reponse_patient})

    return resultats

def create_diagnostic_and_recommandations(resultats, profil_patient, topic):
    rapport_intro = f"Le patient {profil_patient} a r√©pondu aux questions suivantes sur le sujet '{topic}' :\n"
    for i, item in enumerate(resultats, 1):
        rapport_intro += f"{i}. Q: {item['question']}\n   R: {item['reponse']}\n"

    messages = [
        {
            "role": "system",
            "content": (
                "Tu es un m√©decin sp√©cialiste qualifi√©. Analyse attentivement les r√©ponses du patient "
                "et r√©dige un diagnostic clair, d√©taill√© et professionnel, accompagn√© de recommandations concr√®tes."
            )
        },
        {"role": "user", "content": rapport_intro}
    ]

    sablier = Sablier(message="üìã G√©n√©ration du rapport et du diagnostic en cours...")
    sablier.start()
    rapport = chat(messages=messages)  # ‚úÖ mod√®le choisi automatiquement
    sablier.stop()

    print("\nü©∫ Diagnostic et recommandations :\n")
    print(rapport["message"]["content"])

if __name__ == "__main__":
    if PROVIDER == 'ollama':
        launch_model_if_needed()

    topic = input("üîç Saisis le sujet m√©dical √† explorer (ex : diab√®te, asthme...) : ").strip()
    profil = collect_static_patient_info()
    resultats = generate_context_and_questions(topic, profil)
    create_diagnostic_and_recommandations(resultats, profil, topic)
